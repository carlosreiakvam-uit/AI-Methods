{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graded_asignments.graded_2.MLPEnsemble import MLPEnsemble\n",
    "from graded_asignments.graded_2.DTForest import DTForest\n",
    "from graded_asignments.graded_2.utils import *\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5a)\n",
    "*Load the file “data_2022.csv” and create a test set in the same format as the training set you created in (2.a)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pd_2021 = pd.read_csv('data/data_2021.csv')\n",
    "pd_2022 = pd.read_csv('data/data_2022.csv')\n",
    "np_2021 = pd_2021['Demand'].to_numpy()\n",
    "np_2022 = pd_2022['Demand'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5b)\n",
    "*Pick a model from (2, 3, or 4), and use this year’s demand so far to predict the missing values from 26.08.2022 to 31.12.2022. Save the predictions in a list (5 pts)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "forest_size = 200\n",
    "window_size = 10\n",
    "x, y = slide(np_2021, window_size)\n",
    "single_tree = DecisionTreeRegressor()\n",
    "dt_forest = DTForest(forest_size)\n",
    "mlp_forest = MLPEnsemble(forest_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "test_data, train_data = split([pd_2021, pd_2022])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_tree.fit(x, y)  # training single tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...........................................................................................................................................................................................................Finished!"
     ]
    }
   ],
   "source": [
    "dt_forest.train(train_data, window_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...........................................................................................................................................................................................................Finished!"
     ]
    }
   ],
   "source": [
    "mlp_forest.train(train_data, window_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "offset = [None for i in range(window_size)]\n",
    "mlp_pred = mlp_forest.predict(x) + offset\n",
    "dt_pred = dt_forest.predict(x) + offset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def predict_unseen(forest, initial_window, n_predictions) -> list:\n",
    "    complete_pred = initial_window\n",
    "    window = initial_window\n",
    "    for i in range(n_predictions):\n",
    "        current_predictions = []\n",
    "        for model in forest:\n",
    "            pred = model.predict([window])\n",
    "            current_predictions.append(pred[0])\n",
    "        avg_pred = sum(current_predictions) / len(current_predictions)\n",
    "        window = window[1:]\n",
    "        window.append(avg_pred)\n",
    "        complete_pred.append(avg_pred)\n",
    "    return complete_pred\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# SIMON\n",
    "def predict_avg_of_combined(trees, slide):\n",
    "    summed = []\n",
    "    for i in range(len(trees)):\n",
    "        summed.append(trees[i].predict(slide).item())\n",
    "    return round(mean(summed), 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[[123.64, 113.5, 99.96, 83.23, 114.01, 131.72, 201.82, 156.86, 152.42, 147.86]]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_window = np_2021[-10:].reshape(1, -1).tolist()\n",
    "initial_window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "a = np_2022.tolist()\n",
    "for i in range(365 - len(np_2022) - 1):\n",
    "    b = predict_avg_of_combined(dt_forest.forest, initial_window)\n",
    "    a.append(b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. DecisionTreeRegressor expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dt_pred_unseen \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_unseen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdt_forest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m365\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnp_2022\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m dt_pred_2022 \u001B[38;5;241m=\u001B[39m np_2022\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;241m+\u001B[39m dt_pred_unseen\n",
      "Cell \u001B[1;32mIn [9], line 7\u001B[0m, in \u001B[0;36mpredict_unseen\u001B[1;34m(forest, initial_window, n_predictions)\u001B[0m\n\u001B[0;32m      5\u001B[0m current_predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m forest:\n\u001B[1;32m----> 7\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     current_predictions\u001B[38;5;241m.\u001B[39mappend(pred[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      9\u001B[0m avg_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(current_predictions) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(current_predictions)\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:505\u001B[0m, in \u001B[0;36mBaseDecisionTree.predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;124;03m\"\"\"Predict class or regression value for X.\u001B[39;00m\n\u001B[0;32m    483\u001B[0m \n\u001B[0;32m    484\u001B[0m \u001B[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;124;03m    The predicted classes, or the predict values.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    504\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 505\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    506\u001B[0m proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_\u001B[38;5;241m.\u001B[39mpredict(X)\n\u001B[0;32m    507\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:471\u001B[0m, in \u001B[0;36mBaseDecisionTree._validate_X_predict\u001B[1;34m(self, X, check_input)\u001B[0m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;124;03m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001B[39;00m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_input:\n\u001B[1;32m--> 471\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m    473\u001B[0m         X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc\n\u001B[0;32m    474\u001B[0m     ):\n\u001B[0;32m    475\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\base.py:577\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 577\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    578\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    890\u001B[0m     )\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m--> 893\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    895\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    896\u001B[0m     )\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m    899\u001B[0m     _assert_all_finite(\n\u001B[0;32m    900\u001B[0m         array,\n\u001B[0;32m    901\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    902\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    903\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    904\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with dim 3. DecisionTreeRegressor expected <= 2."
     ]
    }
   ],
   "source": [
    "#dt_pred_unseen = predict_unseen(dt_forest.forest, initial_window, 365 - len(np_2022))\n",
    "#dt_pred_2022 = np_2022.tolist() + dt_pred_unseen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# initial_window = np_2021[-10:].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. MLPRegressor expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m mlp_pred_unseen \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_unseen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmlp_forest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensemble\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m365\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnp_2022\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m mlp_pred_2022 \u001B[38;5;241m=\u001B[39m np_2022\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;241m+\u001B[39m mlp_pred_unseen\n",
      "Cell \u001B[1;32mIn [9], line 7\u001B[0m, in \u001B[0;36mpredict_unseen\u001B[1;34m(forest, initial_window, n_predictions)\u001B[0m\n\u001B[0;32m      5\u001B[0m current_predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m forest:\n\u001B[1;32m----> 7\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     current_predictions\u001B[38;5;241m.\u001B[39mappend(pred[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      9\u001B[0m avg_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(current_predictions) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(current_predictions)\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1591\u001B[0m, in \u001B[0;36mMLPRegressor.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1578\u001B[0m \u001B[38;5;124;03m\"\"\"Predict using the multi-layer perceptron model.\u001B[39;00m\n\u001B[0;32m   1579\u001B[0m \n\u001B[0;32m   1580\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1588\u001B[0m \u001B[38;5;124;03m    The predicted values.\u001B[39;00m\n\u001B[0;32m   1589\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1590\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m-> 1591\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_pass_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1592\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_pred\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1593\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y_pred\u001B[38;5;241m.\u001B[39mravel()\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:160\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_pass_fast\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;124;03m\"\"\"Predict using the trained model\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m    This is the same as _forward_pass but does not record the activations\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m        The decision function of the samples for each class in the model.\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 160\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# Initialize first layer\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     activation \u001B[38;5;241m=\u001B[39m X\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\base.py:577\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    575\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 577\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    578\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[1;32mC:\\UIT_repos\\methods\\ai_methods\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    890\u001B[0m     )\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nd \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m--> 893\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    895\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    896\u001B[0m     )\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m    899\u001B[0m     _assert_all_finite(\n\u001B[0;32m    900\u001B[0m         array,\n\u001B[0;32m    901\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    902\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    903\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    904\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with dim 3. MLPRegressor expected <= 2."
     ]
    }
   ],
   "source": [
    " mlp_pred_unseen = predict_unseen(mlp_forest.ensemble, initial_window, 365 - len(np_2022))\n",
    "mlp_pred_2022 = np_2022.tolist() + mlp_pred_unseen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5c)\n",
    "*Use matplotlib to plot the predictions for the remainder of 2022 (5 pts)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_pred_2022' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mdt_pred_2022\u001B[49m, mlp_pred_2022)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dt_pred_2022' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(dt_pred_2022, mlp_pred_2022)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
